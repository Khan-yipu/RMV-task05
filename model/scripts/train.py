import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR
import time
import os
from tqdm import tqdm
import numpy as np

import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import config
from models.armor_cnn import create_model
from utils.data_loader import get_data_loaders
from utils.visualization import plot_training_curve


class Trainer:
    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = config.DEVICE

        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY,
        )
        # ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=config.NUM_EPOCHS)

        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        self.train_losses = []
        self.val_accuracies = []
        self.best_acc = 0.0

    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        running_loss = 0.0
        progress_bar = tqdm(self.train_loader, desc="Training")

        for batch_idx, (images, labels) in enumerate(progress_bar):
            images, labels = images.to(self.device), labels.to(self.device)

            self.optimizer.zero_grad()
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()

            running_loss += loss.item()

            # æ›´æ–°è¿›åº¦æ¡
            if batch_idx % 10 == 0:
                progress_bar.set_postfix(
                    {
                        "Loss": f"{loss.item():.4f}",
                        "Avg Loss": f"{running_loss / (batch_idx + 1):.4f}",
                    }
                )

        return running_loss / len(self.train_loader)

    def validate(self):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in self.val_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return 100 * correct / total

    def train(self, num_epochs):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒé›†å¤§å°: {len(self.train_loader.dataset)}")
        print(f"éªŒè¯é›†å¤§å°: {len(self.val_loader.dataset)}")
        print(f"æ‰¹æ¬¡å¤§å°: {config.BATCH_SIZE}")
        print(f"å­¦ä¹ ç‡: {config.LEARNING_RATE}")
        print("-" * 60)

        start_time = time.time()

        for epoch in range(num_epochs):
            print(f"\nEpoch [{epoch + 1}/{num_epochs}]")
            print("-" * 40)

            # è®­ç»ƒ
            epoch_loss = self.train_epoch()
            self.train_losses.append(epoch_loss)

            # éªŒè¯
            accuracy = self.validate()
            self.val_accuracies.append(accuracy)

            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            current_lr = self.optimizer.param_groups[0]["lr"]

            print(f"è®­ç»ƒæŸå¤±: {epoch_loss:.4f}")
            print(f"éªŒè¯å‡†ç¡®ç‡: {accuracy:.2f}%")
            print(f"å­¦ä¹ ç‡: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if accuracy > self.best_acc:
                self.best_acc = accuracy
                model_path = os.path.join(config.MODEL_SAVE_DIR, "best_model.pth")
                torch.save(
                    {
                        "epoch": epoch + 1,
                        "model_state_dict": self.model.state_dict(),
                        "optimizer_state_dict": self.optimizer.state_dict(),
                        "accuracy": accuracy,
                        "loss": epoch_loss,
                    },
                    model_path,
                )
                print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {accuracy:.2f}%")

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(config.MODEL_SAVE_DIR, "final_model.pth")
        torch.save(self.model.state_dict(), final_model_path)

        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        total_time = time.time() - start_time
        print(f"\nè®­ç»ƒå®Œæˆ!")
        print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time // 60:.0f}m {total_time % 60:.0f}s")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_acc:.2f}%")

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        curve_path = os.path.join(config.LOG_DIR, "training_curve.png")
        plot_training_curve(
            self.train_losses, self.val_accuracies, save_path=curve_path
        )

        return self.best_acc


def main():
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)

    try:
        # è·å–æ•°æ®åŠ è½½å™¨
        train_loader, val_loader = get_data_loaders()

        # åˆ›å»ºæ¨¡å‹
        model = create_model(num_classes=config.NUM_CLASSES, model_type="standard")
        model = model.to(config.DEVICE)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print("æ¨¡å‹ç»“æ„:")
        print(model)
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"æ€»å‚æ•°é‡: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")

        # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
        trainer = Trainer(model, train_loader, val_loader)
        best_accuracy = trainer.train(config.NUM_EPOCHS)

        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()
