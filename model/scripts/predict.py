import torch
from PIL import Image
import torch.nn.functional as F
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np
import os
import glob

import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import config
from models.armor_cnn import create_model


class Predictor:
    def __init__(self, model_path):
        self.model = create_model(num_classes=config.NUM_CLASSES)

        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=config.DEVICE)
            if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
                self.model.load_state_dict(checkpoint["model_state_dict"])
            else:
                self.model.load_state_dict(checkpoint)
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        self.model = self.model.to(config.DEVICE)
        self.model.eval()

        self.transform = transforms.Compose(
            [
                transforms.Resize(config.IMAGE_SIZE),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                ),
            ]
        )

        self.class_names = [str(i) for i in range(1, config.NUM_CLASSES + 1)]
        print(f"âœ… é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {os.path.basename(model_path)}")

    def predict(self, image_path):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        # åŠ è½½å›¾åƒ
        try:
            image = Image.open(image_path).convert("RGB")
            original_size = image.size
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½å›¾åƒ {image_path}: {e}")
            return None, None, None, None

        # é¢„å¤„ç†
        image_tensor = self.transform(image).unsqueeze(0).to(config.DEVICE)

        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)

            predicted_class = predicted.item()
            confidence_score = confidence.item()

            # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
            all_probs = probabilities.squeeze().cpu().numpy()

        return predicted_class, confidence_score, all_probs, image, original_size

    def display_prediction(self, image_path):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        result = self.predict(image_path)
        if result[0] is None:
            return

        predicted_class, confidence, all_probs, image, original_size = result

        # æ˜¾ç¤ºç»“æœ
        plt.figure(figsize=(15, 5))

        # æ˜¾ç¤ºåŸå›¾åƒ
        plt.subplot(1, 3, 1)
        plt.imshow(image)
        plt.title(f"åŸå›¾åƒ ({original_size[0]}Ã—{original_size[1]})", fontsize=12)
        plt.axis("off")

        # æ˜¾ç¤ºé¢„å¤„ç†åçš„å›¾åƒ
        plt.subplot(1, 3, 2)
        processed_image = self.transform(image).numpy().transpose((1, 2, 0))
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        processed_image = std * processed_image + mean
        processed_image = np.clip(processed_image, 0, 1)
        plt.imshow(processed_image)
        plt.title(f"é¢„å¤„ç†å ({config.IMAGE_WIDTH}Ã—{config.IMAGE_HEIGHT})", fontsize=12)
        plt.axis("off")

        # æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(1, 3, 3)
        colors = [
            "lightcoral" if i != predicted_class else "lightgreen"
            for i in range(len(all_probs))
        ]
        bars = plt.bar(self.class_names, all_probs, color=colors, alpha=0.7)
        plt.ylim(0, 1)
        plt.title("å„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ", fontsize=12, fontweight="bold")
        plt.xlabel("æ•°å­—ç±»åˆ«", fontsize=11)
        plt.ylabel("æ¦‚ç‡", fontsize=11)
        plt.grid(True, alpha=0.3)

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ¦‚ç‡å€¼
        for bar, prob in zip(bars, all_probs):
            plt.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{prob:.4f}",
                ha="center",
                va="bottom",
                fontsize=9,
            )

        plt.tight_layout()
        plt.show()

        # æ‰“å°è¯¦ç»†ç»“æœ
        print(f"\nğŸ“ˆ é¢„æµ‹ç»“æœ:")
        print(f"  å›¾åƒ: {os.path.basename(image_path)}")
        print(f"  é¢„æµ‹æ•°å­—: {self.class_names[predicted_class]}")
        print(f"  ç½®ä¿¡åº¦: {confidence:.4f}")
        print(f"  åŸå§‹å°ºå¯¸: {original_size}")
        print(f"\næ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
        for i, prob in enumerate(all_probs):
            status = "âœ…" if i == predicted_class else "  "
            print(f"  {status} æ•°å­— {self.class_names[i]}: {prob:.4f}")


def main():
    # åˆ›å»ºé¢„æµ‹å™¨
    model_path = os.path.join(config.MODEL_SAVE_DIR, "best_model.pth")

    if not os.path.exists(model_path):
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ train.py")
        return

    predictor = Predictor(model_path)

    # äº¤äº’å¼é¢„æµ‹
    while True:
        print("\n" + "=" * 60)
        print("è£…ç”²æ¿æ•°å­—è¯†åˆ«é¢„æµ‹ç³»ç»Ÿ")
        print("=" * 60)
        print("1. è¾“å…¥å›¾ç‰‡è·¯å¾„è¿›è¡Œé¢„æµ‹")
        print("2. è¾“å…¥ 'sample' æµ‹è¯•æ ·ä¾‹å›¾ç‰‡")
        print("3. è¾“å…¥ 'quit' é€€å‡º")

        user_input = input("\nè¯·é€‰æ‹©æ“ä½œ: ").strip()

        if user_input.lower() == "quit":
            print("å†è§ï¼")
            break
        elif user_input.lower() == "sample":
            # æŸ¥æ‰¾æ ·ä¾‹å›¾ç‰‡
            sample_dirs = [config.TRAIN_DIR, config.TEST_DIR]
            sample_images = []
            for sample_dir in sample_dirs:
                if os.path.exists(sample_dir):
                    for class_dir in glob.glob(os.path.join(sample_dir, "*")):
                        if os.path.isdir(class_dir):
                            images = (
                                glob.glob(os.path.join(class_dir, "*.jpg"))
                                + glob.glob(os.path.join(class_dir, "*.png"))
                                + glob.glob(os.path.join(class_dir, "*.jpeg"))
                            )
                            sample_images.extend(images[:2])  # æ¯ç±»å–2å¼ 

            if sample_images:
                import random

                sample_image = random.choice(sample_images)
                print(f"ä½¿ç”¨æ ·ä¾‹å›¾ç‰‡: {sample_image}")
                predictor.display_prediction(sample_image)
            else:
                print("æœªæ‰¾åˆ°æ ·ä¾‹å›¾ç‰‡")
        else:
            image_path = user_input
            if not os.path.exists(image_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                continue

            predictor.display_prediction(image_path)


if __name__ == "__main__":
    main()
