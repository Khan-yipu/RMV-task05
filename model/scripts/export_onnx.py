import os
import sys
import torch
import torch.onnx
import onnx
import onnxruntime as ort
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import config
from models.armor_cnn import create_model


class ONNXExporter:
    def __init__(self, model_path):
        self.model_path = model_path
        self.device = config.DEVICE
        self.model = create_model(num_classes=config.NUM_CLASSES)

        # åŠ è½½æ¨¡å‹
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device)
            if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
                self.model.load_state_dict(checkpoint["model_state_dict"])
            else:
                self.model.load_state_dict(checkpoint)
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        self.model.to(self.device)
        self.model.eval()

    def export_onnx(self, onnx_path=None):
        """å¯¼å‡ºONNXæ¨¡å‹"""
        if onnx_path is None:
            base_name = os.path.splitext(os.path.basename(self.model_path))[0]
            onnx_path = os.path.join(config.MODEL_SAVE_DIR, f"{base_name}.onnx")

        # åˆ›å»ºç¤ºä¾‹è¾“å…¥
        dummy_input = torch.randn(1, 3, config.IMAGE_HEIGHT, config.IMAGE_WIDTH).to(
            self.device
        )

        try:
            # æ–¹æ³•1: ä½¿ç”¨æ–°çš„ torch.export æ–¹æ³• (PyTorch 2.0+)
            print("å°è¯•ä½¿ç”¨æ–°çš„ torch.export æ–¹æ³•...")
            torch.onnx.export(
                self.model,
                dummy_input,
                onnx_path,
                export_params=True,
                opset_version=14,  # ä½¿ç”¨æ›´æ–°çš„opset
                do_constant_folding=True,
                input_names=["input"],
                output_names=["output"],
                dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
                verbose=False,
            )

        except Exception as e1:
            print(f"æ–°æ–¹æ³•å¤±è´¥: {e1}")
            print("å°è¯•ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•...")
            try:
                # æ–¹æ³•2: ä¼ ç»Ÿæ–¹æ³•
                torch.onnx.export(
                    self.model,
                    dummy_input,
                    onnx_path,
                    export_params=True,
                    opset_version=12,
                    do_constant_folding=True,
                    input_names=["input"],
                    output_names=["output"],
                    dynamic_axes={
                        "input": {0: "batch_size"},
                        "output": {0: "batch_size"},
                    },
                    verbose=False,
                )
            except Exception as e2:
                print(f"ä¼ ç»Ÿæ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                raise

        print(f"âœ… ONNXæ¨¡å‹å·²å¯¼å‡º: {onnx_path}")
        return onnx_path

    def export_onnx_dynamo(self, onnx_path=None):
        """ä½¿ç”¨ torch.export (PyTorch 2.0+ çš„æ–°æ–¹æ³•)"""
        if onnx_path is None:
            base_name = os.path.splitext(os.path.basename(self.model_path))[0]
            onnx_path = os.path.join(config.MODEL_SAVE_DIR, f"{base_name}_dynamo.onnx")

        try:
            import torch._dynamo

            # åˆ›å»ºç¤ºä¾‹è¾“å…¥
            dummy_input = torch.randn(1, 3, config.IMAGE_HEIGHT, config.IMAGE_WIDTH).to(
                self.device
            )

            # ä½¿ç”¨ torch.export æ–¹æ³•
            exported_program = torch.export.export(self.model, (dummy_input,))
            torch.onnx.dynamo_export(exported_program, dummy_input).save(onnx_path)

            print(f"âœ… Dynamo ONNXæ¨¡å‹å·²å¯¼å‡º: {onnx_path}")
            return onnx_path

        except Exception as e:
            print(f"âŒ Dynamoå¯¼å‡ºå¤±è´¥: {e}")
            return None

    def validate_onnx(self, onnx_path):
        """éªŒè¯ONNXæ¨¡å‹"""
        try:
            # åŠ è½½ONNXæ¨¡å‹
            onnx_model = onnx.load(onnx_path)
            onnx.checker.check_model(onnx_model)
            print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡")

            # ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†æµ‹è¯•
            ort_session = ort.InferenceSession(onnx_path)

            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            test_input = torch.randn(
                1, 3, config.IMAGE_HEIGHT, config.IMAGE_WIDTH
            ).numpy()

            # ONNXæ¨ç†
            ort_inputs = {ort_session.get_inputs()[0].name: test_input}
            ort_outputs = ort_session.run(None, ort_inputs)

            # PyTorchæ¨ç†
            with torch.no_grad():
                torch_input = torch.from_numpy(test_input).to(self.device)
                torch_output = self.model(torch_input).cpu().numpy()

            # æ¯”è¾ƒç»“æœ
            diff = np.abs(ort_outputs[0] - torch_output).max()
            print(f"âœ… ONNXå’ŒPyTorchè¾“å‡ºå·®å¼‚: {diff:.6f}")

            if diff < 1e-5:
                print("ğŸ‰ ONNXæ¨¡å‹éªŒè¯æˆåŠŸï¼è¾“å‡ºä¸€è‡´")
            else:
                print("âš ï¸ ONNXæ¨¡å‹è¾“å‡ºæœ‰å¾®å°å·®å¼‚ï¼Œä½†åœ¨å¯æ¥å—èŒƒå›´å†…")

            return True

        except Exception as e:
            print(f"âŒ ONNXæ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°ï¼šå¯¼å‡ºå’ŒéªŒè¯ONNXæ¨¡å‹"""
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        os.path.join(config.MODEL_SAVE_DIR, "best_model.pth"),
        os.path.join(config.MODEL_SAVE_DIR, "final_model.pth"),
    ]

    for model_file in model_files:
        if os.path.exists(model_file):
            print(f"\n{'=' * 50}")
            print(f"å¤„ç†æ¨¡å‹: {os.path.basename(model_file)}")
            print(f"{'=' * 50}")

            try:
                # åˆ›å»ºå¯¼å‡ºå™¨
                exporter = ONNXExporter(model_file)

                # å¯¼å‡ºONNX
                onnx_path = exporter.export_onnx()

                # éªŒè¯ONNX
                exporter.validate_onnx(onnx_path)

                # å°è¯•æ–°çš„å¯¼å‡ºæ–¹æ³•
                # dynamo_path = exporter.export_onnx_dynamo()
                # if dynamo_path:
                #     exporter.validate_onnx(dynamo_path)

            except Exception as e:
                print(f"âŒ å¤„ç† {model_file} æ—¶å‡ºé”™: {e}")
                import traceback

                traceback.print_exc()
        else:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")

    print(f"\nğŸ‰ ONNXå¯¼å‡ºå®Œæˆï¼")
    print(f"ONNXæ¨¡å‹ä¿å­˜åœ¨: {config.MODEL_SAVE_DIR}")


if __name__ == "__main__":
    main()
